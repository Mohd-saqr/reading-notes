# Ethics

## ACM Code of Ethics and Professional Conduct
The Code is designed to inspire and guide the ethical conduct of all computing professionals, including current and aspiring practitioners, instructors, students, influencers, and anyone who uses computing technology in an impactful way. Additionally, the Code serves as a basis for remediation when violations occur. The Code includes principles formulated as statements of responsibility, based on the understanding that the public good is always the primary consideration. Each principle is supplemented by guidelines, which provide explanations to assist computing professionals in understanding and applying the principle.

## GENERAL ETHICAL PRINCIPLES

1 - Contribute to society and to human well-being, acknowledging that all people are stakeholders in computing.

2- Avoid harm 

3- Be honest and trustworthy.

4- Be fair and take action not to discriminate.

5- Respect the work required to produce new ideas, inventions, creative works, and computing artifacts.

6- Respect privacy 

7- Honor confidentiality.


## The Software Engineering Code of Ethics and Professional Practice
Software Engineering Code of Ethics and Professional Practice (Version 5.2) as recommended by the ACM/IEEE-CS Joint Task Force on Software Engineering Ethics and Professional Practices and jointly approved by the ACM and the IEEE-CS as the standard for teaching and practicing software engineering.


###  PRINCIPLES

Software engineers shall act consistently with the public interest. In particular, software engineers shall, as appropriate:


1- Accept full responsibility for their own work. 

2- Moderate the interests of the software engineer, the employer, the client and the users with the public good.

3- Approve software only if they have a well-founded belief that it is safe, meets specifications, passes appropriate tests, and does not diminish quality of life, diminish privacy or harm the environment. The ultimate effect of the work should be to the public good.

4- Disclose to appropriate persons or authorities any actual or potential danger to the user, the public, or the environment, that they reasonably believe to be associated with software or related documents.


# Ethics in the workplace
 ##  Project Dragonfly, Google’s censored search engine : 

 Google is experiencing a “moral and ethical” crisis. That’s the view of hundreds of employees at the tech company, who are protesting the development of a censored search engine for internet users in China.

About 1,400 Google employees — out of the more than 88,000 — signed a letter to company executives this week, seeking more details and transparency about the project and demanding employee input in decisions about what kind of work Google takes on. They also expressed concern that the company is violating its own ethical principles.

“Currently we do not have the information required to make ethically-informed decisions about our work, our projects, and our employment,” they wrote in the letter, obtained by the Intercept and the New York Times.

Only a small group of Google engineers are reportedly developing the platform for Beijing, and information about the project has been so heavily guarded that only a few hundred Google employees even knew about it. Google has declined to comment publicly on Dragonfly, but Google CEO Sundar Pichai defended the project Thursday during a weekly staff meeting, saying that the project for China is merely in the “exploratory” stage.



## Amazon workers demand Jeff Bezos cancel “Recognition” software
 
 Earlier this week, several Amazon shareholders called on the company to stop selling Rekognition to the police. That backlash has now spread among employees as well.

“Our company should not be in the surveillance business; we should not be in the policing business; we should not be in the business of supporting those who monitor and oppress marginalized populations,” the employee letter states.

The Amazon workers’ letter follows employee activism at other major tech firms like Microsoft and Google. Earlier this week, Microsoft employees called on the company to cancel its cloud computing contract with Immigration and Customs Enforcement. CEO Satya Nadella defended Microsoft’s work with ICE, saying that his company merely provided the agency with routine tech services like email, calendar, and messaging.

And earlier this month, Google employees saw the success of internal activism against their company’s artificial intelligence contract with the Pentagon—at a staff meeting in June, Google Cloud CEO Diane Greene announced that the company would not renew its contract for Project Maven, a Defense Department pilot program that uses artificial intelligence to analyze drone footage. Google also announced new ethics principles to govern its artificial intelligence work.


# Ethics in Technology
## Self Driving Car Ethics
Self-driving cars could save tens of thousands of lives each year, Shariff said. But individual fears could slow down acceptance, leaving traditional cars and their human drivers on the road longer to battle it out with autonomous or semi-autonomous cars. Already, the American Automobile Association says three-quarters of U.S. drivers are suspicious of self-driving vehicles. 

“These ethical problems are not just theoretical,” said Patrick Lin, director of the Ethics and Emerging Sciences Group at California Polytechnic State University, who has worked with Ford, Tesla and other autonomous vehicle makers on just such issues.

While he can’t talk about specific discussions, Lin says some automakers “simply deny that ethics is a real problem, without realizing that they’re making ethical judgment calls all the time” in their development, determining what objects the car will "see," how it will predict what those objects will do next and what the car's reaction should be.


## Big Data is our Civil Rights issue
With the new, data-is-abundant model, we collect first and ask questions later. The schema comes after the collection. Indeed, Big Data success stories like Splunk, Palantir, and others are prized because of their ability to make sense of content well after it’s been collected—sometimes called a schema-less query. This means we collect information long before we decide what it’s for.

And this is a dangerous thing.

When bank managers tried to restrict loans to residents of certain areas (known as redlining) Congress stepped in to stop it (with the Fair Housing Act of 1968.) They were able to legislate against discrimination, making it illegal to change loan policy based on someone’s race.


# Resources
 [Code of Ethics](https://www.acm.org/code-of-ethics)

  [Software Engineering Code of Ethics](https://ethics.acm.org/code-of-ethics/software-engineering-code/)

   [Project Dragonfly, Google’s censored search engine](https://www.vox.com/2018/8/17/17704526/google-dragonfly-censored-search-engine-china)

   [Amazon workers demand Jeff Bezos cancel “Recognition” software](https://gizmodo.com/amazon-workers-demand-jeff-bezos-cancel-face-recognitio-1827037509)

 [Self Driving Car Ethics](https://www.freep.com/story/money/cars/2017/11/21/self-driving-cars-ethics/804805001/)
